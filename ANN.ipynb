{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement an Artificial Neural [Network](https://github.com/ABHISHEKSUBHASHSWAMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        # Initialize weights and biases\n",
    "        self.weights = np.random.randn(1, 1)\n",
    "        self.bias = np.random.randn(1)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        # Forward pass\n",
    "        weighted_sum = np.dot(X, self.weights) + self.bias\n",
    "        output = self.sigmoid(weighted_sum)\n",
    "        return output\n",
    "\n",
    "    def backward_propagation(self, X, y_true, output, learning_rate):\n",
    "        # Backward pass\n",
    "        error = y_true - output\n",
    "        d_output = error * self.sigmoid_derivative(output)\n",
    "        d_weights = np.dot(X.T, d_output)\n",
    "        d_bias = np.sum(d_output)\n",
    "\n",
    "        # Update weights and biases\n",
    "        self.weights += learning_rate * d_weights\n",
    "        self.bias += learning_rate * d_bias\n",
    "\n",
    "    def train(self, X, y_true, learning_rate, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            # Forward propagation\n",
    "            output = self.forward_propagation(X)\n",
    "\n",
    "            # Backward propagation\n",
    "            self.backward_propagation(X, y_true, output, learning_rate)\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                loss = np.mean(np.square(y_true - output))\n",
    "                print(f'Epoch: {epoch}, Loss: {loss:.4f}')\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward_propagation(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data=pd.read_csv('data.csv')\n",
    "height = np.array(data.iloc[:,0].values).reshape(-1,1)\n",
    "weight = np.array(data.iloc[:,1].values).reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize data\n",
    "normalized_height = height*(1/np.max(height))\n",
    "normalized_weight = weight*(1/np.max(weight))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.0138\n",
      "Epoch: 100, Loss: 0.0705\n",
      "Epoch: 200, Loss: 0.0705\n",
      "Epoch: 300, Loss: 0.0705\n",
      "Epoch: 400, Loss: 0.0705\n",
      "Epoch: 500, Loss: 0.0705\n",
      "Epoch: 600, Loss: 0.0705\n",
      "Epoch: 700, Loss: 0.0705\n",
      "Epoch: 800, Loss: 0.0705\n",
      "Epoch: 900, Loss: 0.0705\n",
      "Epoch: 1000, Loss: 0.0705\n",
      "Epoch: 1100, Loss: 0.0705\n",
      "Epoch: 1200, Loss: 0.0705\n",
      "Epoch: 1300, Loss: 0.0705\n",
      "Epoch: 1400, Loss: 0.0705\n",
      "Epoch: 1500, Loss: 0.0705\n",
      "Epoch: 1600, Loss: 0.0705\n",
      "Epoch: 1700, Loss: 0.0705\n",
      "Epoch: 1800, Loss: 0.0705\n",
      "Epoch: 1900, Loss: 0.0705\n",
      "Epoch: 2000, Loss: 0.0705\n",
      "Epoch: 2100, Loss: 0.0705\n",
      "Epoch: 2200, Loss: 0.0705\n",
      "Epoch: 2300, Loss: 0.0705\n",
      "Epoch: 2400, Loss: 0.0705\n",
      "Epoch: 2500, Loss: 0.0705\n",
      "Epoch: 2600, Loss: 0.0705\n",
      "Epoch: 2700, Loss: 0.0705\n",
      "Epoch: 2800, Loss: 0.0705\n",
      "Epoch: 2900, Loss: 0.0705\n",
      "Epoch: 3000, Loss: 0.0705\n",
      "Epoch: 3100, Loss: 0.0705\n",
      "Epoch: 3200, Loss: 0.0705\n",
      "Epoch: 3300, Loss: 0.0705\n",
      "Epoch: 3400, Loss: 0.0705\n",
      "Epoch: 3500, Loss: 0.0705\n",
      "Epoch: 3600, Loss: 0.0705\n",
      "Epoch: 3700, Loss: 0.0705\n",
      "Epoch: 3800, Loss: 0.0705\n",
      "Epoch: 3900, Loss: 0.0705\n",
      "Epoch: 4000, Loss: 0.0705\n",
      "Epoch: 4100, Loss: 0.0705\n",
      "Epoch: 4200, Loss: 0.0705\n",
      "Epoch: 4300, Loss: 0.0705\n",
      "Epoch: 4400, Loss: 0.0705\n",
      "Epoch: 4500, Loss: 0.0705\n",
      "Epoch: 4600, Loss: 0.0705\n",
      "Epoch: 4700, Loss: 0.0705\n",
      "Epoch: 4800, Loss: 0.0705\n",
      "Epoch: 4900, Loss: 0.0705\n",
      "Epoch: 5000, Loss: 0.0705\n",
      "Epoch: 5100, Loss: 0.0705\n",
      "Epoch: 5200, Loss: 0.0705\n",
      "Epoch: 5300, Loss: 0.0705\n",
      "Epoch: 5400, Loss: 0.0705\n",
      "Epoch: 5500, Loss: 0.0705\n",
      "Epoch: 5600, Loss: 0.0705\n",
      "Epoch: 5700, Loss: 0.0705\n",
      "Epoch: 5800, Loss: 0.0705\n",
      "Epoch: 5900, Loss: 0.0705\n",
      "Epoch: 6000, Loss: 0.0705\n",
      "Epoch: 6100, Loss: 0.0705\n",
      "Epoch: 6200, Loss: 0.0705\n",
      "Epoch: 6300, Loss: 0.0705\n",
      "Epoch: 6400, Loss: 0.0705\n",
      "Epoch: 6500, Loss: 0.0705\n",
      "Epoch: 6600, Loss: 0.0705\n",
      "Epoch: 6700, Loss: 0.0705\n",
      "Epoch: 6800, Loss: 0.0705\n",
      "Epoch: 6900, Loss: 0.0705\n",
      "Epoch: 7000, Loss: 0.0705\n",
      "Epoch: 7100, Loss: 0.0705\n",
      "Epoch: 7200, Loss: 0.0705\n",
      "Epoch: 7300, Loss: 0.0705\n",
      "Epoch: 7400, Loss: 0.0705\n",
      "Epoch: 7500, Loss: 0.0705\n",
      "Epoch: 7600, Loss: 0.0705\n",
      "Epoch: 7700, Loss: 0.0705\n",
      "Epoch: 7800, Loss: 0.0705\n",
      "Epoch: 7900, Loss: 0.0705\n",
      "Epoch: 8000, Loss: 0.0705\n",
      "Epoch: 8100, Loss: 0.0705\n",
      "Epoch: 8200, Loss: 0.0705\n",
      "Epoch: 8300, Loss: 0.0705\n",
      "Epoch: 8400, Loss: 0.0705\n",
      "Epoch: 8500, Loss: 0.0705\n",
      "Epoch: 8600, Loss: 0.0705\n",
      "Epoch: 8700, Loss: 0.0705\n",
      "Epoch: 8800, Loss: 0.0705\n",
      "Epoch: 8900, Loss: 0.0705\n",
      "Epoch: 9000, Loss: 0.0705\n",
      "Epoch: 9100, Loss: 0.0705\n",
      "Epoch: 9200, Loss: 0.0705\n",
      "Epoch: 9300, Loss: 0.0705\n",
      "Epoch: 9400, Loss: 0.0705\n",
      "Epoch: 9500, Loss: 0.0705\n",
      "Epoch: 9600, Loss: 0.0705\n",
      "Epoch: 9700, Loss: 0.0705\n",
      "Epoch: 9800, Loss: 0.0705\n",
      "Epoch: 9900, Loss: 0.0705\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create and train the neural network\n",
    "model = NeuralNetwork()\n",
    "model.train(normalized_height, normalized_weight, learning_rate=0.1, epochs=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted weight for height 177.83739 cm: 77.53 kg\n",
      "True weight for height 177.83739 cm: 61.90 kg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predict weight for a new height value\n",
    "row=7\n",
    "n_height = np.array(data.iloc[row,0])\n",
    "n_weight = np.array(data.iloc[row,1])\n",
    "normalized_height = n_height  * (1/np.max(height))\n",
    "predicted_weight = model.predict(normalized_height) * np.max(weight)\n",
    "print(f'Predicted weight for height {n_height} cm: {predicted_weight[0][0]:.2f} kg')\n",
    "print(f'True weight for height {n_height} cm: {n_weight:.2f} kg')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
