{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Reinforcement Learning Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of RL terminologies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define your QLearning class\n",
    "class QLearning:\n",
    "    def __init__(self, state_space, action_space, learning_rate, discount_factor):\n",
    "        self.state_space = state_space\n",
    "        self.action_space = action_space\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.q_table = np.zeros((state_space, action_space))\n",
    "\n",
    "    def get_action(self, state, epsilon):\n",
    "        if np.random.rand() < epsilon:\n",
    "            return np.random.choice(self.action_space)  # Random action (exploration)\n",
    "        else:\n",
    "            return np.argmax(self.q_table[state])  # Exploitation using learned Q-values\n",
    "\n",
    "    def update_q_table(self, state, action, reward, next_state):\n",
    "        old_value = self.q_table[state, action]\n",
    "        next_max = np.max(self.q_table[next_state])\n",
    "        new_value = (1 - self.learning_rate) * old_value + self.learning_rate * (reward + self.discount_factor * next_max)\n",
    "        self.q_table[state, action] = new_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 18544.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Q-table:\n",
      "[[26.59612402 26.62478417 26.598401   27.02019464]\n",
      " [26.54215703 26.5325388  26.88811188 26.53009904]\n",
      " [26.53513699 26.4886326  26.52049472 27.32266776]\n",
      " [26.6036865  26.56117206 26.80018192 26.66500551]\n",
      " [27.08214962 26.55504005 26.55245073 26.4486053 ]\n",
      " [26.53188503 26.71258365 26.54135352 26.82801822]\n",
      " [26.59497875 26.54551248 26.92728842 26.57705163]\n",
      " [26.5434918  26.92533249 26.47621987 26.50384238]\n",
      " [24.22957191 25.01815374 26.83266818 21.58941471]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define your specific state space, action space, learning rate, and discount factor\n",
    "state_space = 9  # number of states\n",
    "action_space = 4  # number of actions\n",
    "learning_rate = 0.2\n",
    "discount_factor = 0.99\n",
    "\n",
    "# Create an instance of the QLearning class\n",
    "ql = QLearning(state_space, action_space, learning_rate, discount_factor)\n",
    "\n",
    "# Simulate a number of episodes using tqdm for progress visualization\n",
    "num_episodes = 10000\n",
    "epsilon = 0.5  # Initial exploration rate\n",
    "min_epsilon = 0.01  # Minimum exploration rate\n",
    "decay_rate = 0.001  # Exploration rate decay\n",
    "rewards = np.random.randn(state_space)  # Define random rewards for each state\n",
    "\n",
    "for episode in tqdm(range(num_episodes)):\n",
    "    state = np.random.randint(0, state_space)\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = ql.get_action(state, epsilon)\n",
    "\n",
    "        # Simulate a transition - here, just a random transition for demonstration\n",
    "        next_state = np.random.randint(0, state_space)\n",
    "        reward = rewards[next_state]  # Use the defined rewards\n",
    "\n",
    "        ql.update_q_table(state, action, reward, next_state)\n",
    "        state = next_state\n",
    "\n",
    "        if state == state_space - 1:\n",
    "            done = True\n",
    "\n",
    "    # Decay exploration rate epsilon\n",
    "    epsilon = min_epsilon + (1 - min_epsilon) * np.exp(-decay_rate * episode)\n",
    "\n",
    "print(\"Final Q-table:\")\n",
    "print(ql.q_table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
