{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program for Recommendation System "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Surprise Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-surprise\n",
      "  Downloading scikit-surprise-1.1.3.tar.gz (771 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.0/772.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: joblib>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-surprise) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-surprise) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/godspeed/Library/Python/3.9/lib/python/site-packages (from scikit-surprise) (1.10.1)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.3-cp39-cp39-macosx_10_9_universal2.whl size=1585307 sha256=b3a366437055ea9f6a22fc6c6872cceaa1d650e39e6beb71b96e409e60fd2b47\n",
      "  Stored in directory: /Users/godspeed/Library/Caches/pip/wheels/c6/3a/46/9b17b3512bdf283c6cb84f59929cdd5199d4e754d596d22784\n",
      "Successfully built scikit-surprise\n",
      "Installing collected packages: scikit-surprise\n",
      "Successfully installed scikit-surprise-1.1.3\n"
     ]
    }
   ],
   "source": [
    "# !pip install scikit-surprise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9430\n",
      "Top 5 recommended movies for user 196:\n",
      "Movie ID: 773, Predicted Rating: 3.47\n",
      "Movie ID: 1028, Predicted Rating: 3.47\n",
      "Movie ID: 1078, Predicted Rating: 3.47\n",
      "Movie ID: 421, Predicted Rating: 3.47\n",
      "Movie ID: 288, Predicted Rating: 3.47\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "# Load the MovieLens dataset\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "# Define the algorithm (Singular Value Decomposition - SVD)\n",
    "algo = SVD()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "# Train the algorithm on the training set\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "accuracy.rmse(predictions)\n",
    "\n",
    "# Get recommendations for a specific user (user ID: 196)\n",
    "user_id = str(196)\n",
    "user_ratings = [(trainset.to_raw_iid(item), algo.predict(user_id, item).est) for item in trainset.all_items() if item not in trainset.ur[trainset.to_inner_uid(user_id)]]\n",
    "sorted_ratings = sorted(user_ratings, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"Top 5 recommended movies for user {user_id}:\")\n",
    "for movie_id, predicted_rating in sorted_ratings[:5]:\n",
    "    print(f\"Movie ID: {movie_id}, Predicted Rating: {predicted_rating:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for User 2: [(0, 2.67), (2, 2.67), (4, 1.67)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class CollaborativeFiltering:\n",
    "    def __init__(self, num_users, num_items):\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.user_item_matrix = np.zeros((num_users, num_items))\n",
    "        self.similarity_matrix = np.zeros((num_users, num_users))\n",
    "\n",
    "    def add_interaction(self, user_id, item_id, rating):\n",
    "        self.user_item_matrix[user_id, item_id] = rating\n",
    "\n",
    "    def calculate_similarity(self):\n",
    "        for i in range(self.num_users):\n",
    "            for j in range(self.num_users):\n",
    "                if i != j:\n",
    "                    # Calculate cosine similarity between users i and j\n",
    "                    numerator = np.dot(self.user_item_matrix[i], self.user_item_matrix[j])\n",
    "                    denominator = np.linalg.norm(self.user_item_matrix[i]) * np.linalg.norm(self.user_item_matrix[j])\n",
    "                    self.similarity_matrix[i, j] = numerator / (denominator + 1e-10)\n",
    "\n",
    "    def recommend_items(self, user_id, num_recommendations=5):\n",
    "        # Find the most similar users to the target user\n",
    "        similar_users = np.argsort(self.similarity_matrix[user_id])[::-1]\n",
    "\n",
    "        # Identify items that the target user hasn't interacted with\n",
    "        unrated_items = np.where(self.user_item_matrix[user_id] == 0)[0]\n",
    "\n",
    "        # Recommend items based on the most similar users\n",
    "        recommendations = []\n",
    "        for item_id in unrated_items[:num_recommendations]:\n",
    "            predicted_rating = np.mean(self.user_item_matrix[similar_users[:3], item_id])\n",
    "            recommendations.append((item_id, round(predicted_rating,2)))\n",
    "\n",
    "        # Sort recommendations by predicted rating\n",
    "        recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        return recommendations\n",
    "\n",
    "# Example usage\n",
    "num_users = 4\n",
    "num_items = 5\n",
    "\n",
    "# Create a CollaborativeFiltering instance\n",
    "cf = CollaborativeFiltering(num_users, num_items)\n",
    "\n",
    "# Add user-item interactions (user_id, item_id, rating)\n",
    "interactions = [\n",
    "    (0, 0, 5), (0, 1, 4), (0, 3, 2),\n",
    "    (1, 0, 3), (1, 2, 5), (1, 3, 1),\n",
    "    (2, 1, 2), (2, 3, 4),\n",
    "    (3, 2, 3), (3, 4, 5)\n",
    "]\n",
    "\n",
    "for user, item, rating in interactions:\n",
    "    cf.add_interaction(user, item, rating)\n",
    "\n",
    "# Calculate user similarity\n",
    "cf.calculate_similarity()\n",
    "\n",
    "# Recommend items for a specific user\n",
    "user_id_to_recommend = 2\n",
    "recommendations = cf.recommend_items(user_id_to_recommend, num_recommendations=3)\n",
    "\n",
    "print(f\"Recommendations for User {user_id_to_recommend}: {recommendations}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
